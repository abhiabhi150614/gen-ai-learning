{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "AZ7zusdi0ynx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Runnable(ABC):\n",
        "  @abstractmethod\n",
        "  def invoke(input_data):\n",
        "    pass"
      ],
      "metadata": {
        "id": "W4-u0Kvf0_ye"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bLv79dy3qvdo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class AbhishekLLM(Runnable):\n",
        "  def __init__(self):\n",
        "    print(\"llm created\")\n",
        "  def predict(self,prompt):\n",
        "    response_list = [\n",
        "        \"Delhi is the capital of india\",\n",
        "        \"ipl is a cricket league\",\n",
        "        \"ai means artificial inteligence\"\n",
        "    ]\n",
        "\n",
        "    return {'response':random.choice(response_list)}\n",
        "  def invoke(self,input_data):\n",
        "    return self.predict(input_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = AbhishekLLM()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL4lCINf18iC",
        "outputId": "264cd466-b2c8-4116-b7e3-05a7568ac96c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AbhishekPromptTemplate(Runnable):\n",
        "  def __init__(self,template,input_variables):\n",
        "    self.template = template\n",
        "    self.input_variables = input_variables\n",
        "  def format(self,input_dict):\n",
        "    return self.template.format(**input_dict)\n",
        "  def invoke(self,input_dict):\n",
        "    return self.format(input_dict)\n",
        "\n",
        "\n",
        "b = AbhishekPromptTemplate(\n",
        "    template = \"what is the capital of {country} in {length}\",\n",
        "    input_variables = [\"country\"]\n",
        ")\n",
        "\n",
        "\n",
        "b.format(input_dict = {\"country\":\"india\",\"length\":\"short\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lbgfrXvKqyXd",
        "outputId": "6fa92bee-3a69-4375-c1c3-f65073430014"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is the capital of india in short'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RunnableConnector(Runnable):\n",
        "  def __init__(self,runnable_list):\n",
        "    self.runnable_list = runnable_list\n",
        "  def invoke(self,input_data):\n",
        "    output = input_data\n",
        "    for runnable in self.runnable_list:\n",
        "      output = runnable.invoke(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "r_v-6tYn239I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = AbhishekLLM()\n",
        "b = AbhishekPromptTemplate(\n",
        "    template = \"what is the capital of {country} in {length}\",\n",
        "    input_variables = [\"country\"]\n",
        ")\n",
        "chain = RunnableConnector([b,a])\n",
        "chain.invoke({'country':'india','length':'short'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zrF_L9e3j2I",
        "outputId": "968eb294-6836-429d-8ec8-208758a8fc6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm created\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': 'ipl is a cricket league'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template1 = AbhishekPromptTemplate(\n",
        "    template=\"What is the joke for {topic}?\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "template2 = AbhishekPromptTemplate(\n",
        "    template=\"What is the capital of india?\",\n",
        "    input_variables=[]\n",
        ")\n",
        "\n",
        "llm = AbhishekLLM()\n",
        "\n",
        "chain1 = RunnableConnector([template1,llm])\n",
        "chain2 = RunnableConnector([template2,llm])\n",
        "\n",
        "chain = RunnableConnector([chain1,chain2])\n",
        "\n",
        "\n",
        "chain.invoke({'topic':'cricket'})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41RyBkWL4jX3",
        "outputId": "488d7fb7-3b7b-4b5c-97a5-e1cd3f5d17a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm created\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': 'ai means artificial inteligence'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}